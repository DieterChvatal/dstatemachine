{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Version 1.3 (Dieter's Integration to dstatemachine) \n",
    "\n",
    "from bokeh.io import push_notebook, show, output_notebook, save\n",
    "from bokeh.plotting import figure, output_file, show\n",
    "from bokeh.models import LinearAxis, Range1d, HoverTool\n",
    "from bokeh.layouts import column, row, gridplot, layout\n",
    "from bokeh.models import ColumnDataSource, Div\n",
    "from bokeh.models.widgets import Panel, Tabs\n",
    "import bokeh\n",
    "\n",
    "from itertools import cycle\n",
    "import dmyplant2\n",
    "from dmyplant2.dPlot import bokeh_chart, datastr_to_dict, expand_cylinder, shrink_cylinder, load_pltcfg_from_excel,show_val_stats\n",
    "import arrow\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import traceback\n",
    "import matplotlib\n",
    "import sys\n",
    "import warnings\n",
    "import logging\n",
    "import datetime\n",
    "import pytz\n",
    "import os \n",
    "\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
    "\n",
    "logging.basicConfig(\n",
    "    filename='dmyplant.log',\n",
    "    filemode='w',\n",
    "    format='%(asctime)s %(levelname)s, %(message)s',\n",
    "    level=logging.INFO\n",
    ")\n",
    "logging.captureWarnings(True)\n",
    "#hdlr = logging.StreamHandler(sys.stdout)\n",
    "#logging.getLogger().addHandler(hdlr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmyplant2.cred()\n",
    "mp = dmyplant2.MyPlant(0)\n",
    "from urllib3.exceptions import NewConnectionError\n",
    "import urllib\n",
    "import socket\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    class myEngine(dmyplant2.Engine):\n",
    "        @ property\n",
    "        def dash(self):\n",
    "            _dash = dict()\n",
    "            _dash['Name'] = self.Name\n",
    "            _dash['serialNumber'] = self.serialNumber\n",
    "            _dash['Site'] = self.get_property('IB Site Name') \n",
    "            _dash['Engine ID'] = self.get_property('Engine ID')\n",
    "            _dash['Design Number'] = self.get_property('Design Number')\n",
    "            _dash['Engine Type'] = self.get_property('Engine Type')\n",
    "            _dash['Engine Version'] = self.get_property('Engine Version')\n",
    "            _dash['Gas type'] = self.get_property('Gas Type')\n",
    "            _dash['Country'] = self.get_property('Country')\n",
    "            _dash['OPH Engine'] = self.Count_OpHour\n",
    "            _dash['OPH Validation'] = self.oph_parts\n",
    "            _dash['P_nom'] = self.Pmech_nominal\n",
    "            _dash['BMEP'] = self.BMEP\n",
    "            _dash['LOC'] = self.get_dataItem(\n",
    "                'RMD_ListBuffMAvgOilConsume_OilConsumption')\n",
    "            return _dash\n",
    "\n",
    "    dval=dmyplant2.Validation.load_def_excel('./Validation Dashboard/Input_validation_dashboard.xlsx', 'Engines', mp) #Loading of validation engine data from excel\n",
    "    vl = dmyplant2.Validation(mp, dval, lengine=myEngine, cui_log=False)\n",
    "    enginelist=vl.engines\n",
    "    logging.info('Engine properties loaded')\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    if str(e)==\"'Engine' object has no attribute 'asset'\":\n",
    "        print ('Possible cause: No internet connection')\n",
    "    #traceback.print_tb(e.__traceback__)\n",
    "    #sys.exit(1)\n",
    "  \n",
    "finally:\n",
    "    pass\n",
    "    #hdlr.close()\n",
    "    #logging.getLogger().removeHandler(hdlr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading of Variables from Excel automatic creation of variables\n",
    "df_var=pd.read_excel('./Validation Dashboard/Input_validation_dashboard.xlsx', sheet_name='Variables', usecols=['Variable', 'Value']) #loading of relevant excel sheet in DataFrame\n",
    "df_var.dropna(inplace=True)\n",
    "for i in range(len(df_var)):\n",
    "    globals()[df_var.Variable.iloc[i]]=df_var.Value.iloc[i]\n",
    "\n",
    "validation_name=str(validation_name)\n",
    "###check output,\n",
    "#check for cylinder list\n",
    "if display_all_cylinders:\n",
    "    rel_cyl=all\n",
    "else:\n",
    "    try: #see if variable rel_cyl initiated\n",
    "        rel_cyl=[int(y) for y in rel_cyl.split(',')]\n",
    "    except:\n",
    "        try:\n",
    "            rel_cyl=[int(rel_cyl)]\n",
    "        except:\n",
    "            rel_cyl=all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tablist=[]\n",
    "LOC_average_last=[]\n",
    "loadrange=pd.DataFrame(columns=['<20%', '[20%, 40%)', '[40%, 90%)', '>=90%'])\n",
    "starts_oph=pd.DataFrame(columns=['OPH', 'Starts', 'OPH/ Start'])\n",
    "\n",
    "if use_filter:\n",
    "    filterstring=(f'Filter treshold {treshold}%')\n",
    "else:\n",
    "    filterstring=''#No filter applied'\n",
    "\n",
    "for eng_count, eng in enumerate(enginelist): \n",
    "    pltcfg, plt_titles=load_pltcfg_from_excel()\n",
    "\n",
    "    title=eng.Name\n",
    "\n",
    "    if load_all_cylinders==True:\n",
    "        cyl_to_load=all\n",
    "    else:\n",
    "        cyl_to_load=rel_cyl\n",
    "    datastr=[]\n",
    "    for cfg in pltcfg:\n",
    "        for y in cfg:\n",
    "            y=expand_cylinder(y, cyl_to_load, engi=eng)\n",
    "            datastr += y['col']\n",
    "\n",
    "\n",
    "    datastr += ['Operating hours engine','Starts',#manually add interesting dataitems, for specific calculation or x-axis #eventually method with calls if tems requested (for mean, LOC, filter...)\n",
    "    'Power current','Power nominal',#for filter\n",
    "    'Exhaust temperature cyl. average', #for delta values if string has Exhaust temperature delta\n",
    "    'Speed current', #For BMEP\n",
    "    'Starts', #for Starts validation\n",
    "    #Add custom variable: Mention all required values either here or in the definition excel\n",
    "        x_axes] #for value of x_axes\n",
    "\n",
    "    if 'Exhaust temperature delta' in '\\#'.join(datastr): datastr += ['Exhaust temperature'] #Add item if exhaust temperature delta wished\n",
    "    \n",
    "    ans=datastr_to_dict(datastr)\n",
    "    dat=ans[0]\n",
    "\n",
    "    if start_at_valstart:\n",
    "        starttime=eng.val_start\n",
    "    else:\n",
    "        try:\n",
    "            starttime=time_download_start\n",
    "        except:\n",
    "            starttime=eng.val_start\n",
    "    if get_recent_data:\n",
    "        endtime=arrow.utcnow()\n",
    "    else:\n",
    "        try:\n",
    "            endtime=arrow.get(time_download_end)\n",
    "        except:\n",
    "            endtime=arrow.utcnow()\n",
    "    starttime=arrow.get(starttime).to('Europe/Vienna')\n",
    "    endtime=endtime.to('Europe/Vienna')\n",
    "\n",
    "    #print ('Downloading data for '+title)\n",
    "    print(f\"{(eng_count+1):02d}/{len(enginelist):02d}: Downloading data for {str(eng):<60}, Validation Start OPH: {(eng['oph_start'] or 0):>6}, Validation Start Starts Counter: {(eng['starts_start'] or 0):>6}\")\n",
    "    df = eng.hist_data(\n",
    "            itemIds=dat,\n",
    "            p_from=starttime,\n",
    "            p_to=endtime,\n",
    "            timeCycle=timecycle,\n",
    "            silent=True\n",
    "            #, slot=eng_count\n",
    "    )\n",
    "\n",
    "    ##Change Dataframe - make calculations\n",
    "    df.rename(columns = ans[1], inplace = True)\n",
    "    df = df.set_index('datetime')\n",
    "\n",
    "    #Add Column 'Operating hours validation'\n",
    "    df['Operating hours validation'] = df['Operating hours engine'] - (eng['oph_start'] or 0)\n",
    "\n",
    "    #Add Column 'Starts validation'\n",
    "    df['Starts validation'] = df['Starts'] - (eng['starts_start'] or 0)\n",
    "\n",
    "    #Add BMEP\n",
    "    if 'BMEP' in '\\#'.join(datastr):\n",
    "        df['BMEP'] = (1200*df['Power current']/eng.Generator_Efficiency)/(eng.engvol*df['Speed current'])\n",
    "\n",
    "\n",
    "    #Add custom value: Make calculation with syntax equal to examples above\n",
    "    #e.g. df['newName']=df['Operating hours engine]/df['Starts]\n",
    "    ####\n",
    "    ####\n",
    "    ####\n",
    "\n",
    "\n",
    "    #Calculate EGT delta\n",
    "    if 'Exhaust temperature delta' in '\\#'.join(datastr):\n",
    "        for col in df.columns:\n",
    "            if 'Exhaust temperature' in col and any(map(str.isdigit, col)) and not 'delta' in col:\n",
    "                df[f'Exhaust temperature delta cyl. {col[-2:]}']=df[col].sub(df['Exhaust temperature cyl. average'])\n",
    "\n",
    "    #Add LOC_average, LOC_raw\n",
    "    if 'LOC' in '\\#'.join(datastr):\n",
    "        dfres=eng.timestamp_LOC(starttime, endtime, windowsize=average_hours_LOC, return_OPH=True)\n",
    "        dfres.index = pd.to_datetime(dfres.index)\n",
    "        #print('Merging dfres and df ...')\n",
    "        #print(f'dfres.index.dtype = {dfres.index.dtype}')\n",
    "        #print(f'df.index.dtype = {df.index.dtype}')\n",
    "        \n",
    "        df.sort_index(inplace=True) #additional sorting of index\n",
    "        df=pd.merge_asof(df, dfres, left_index=True, right_index=True)\n",
    "\n",
    "        duplicated=df.duplicated(subset=['LOC_average'])\n",
    "        df.loc[duplicated, ['LOC_average']] = np.NaN\n",
    "        df['LOC_average'] = df['LOC_average'].interpolate()\n",
    "\n",
    "        if interpolate_raw_LOC:\n",
    "            duplicated_raw=df.duplicated(subset=['LOC_raw'])\n",
    "            df.loc[duplicated_raw, ['LOC_raw']] = np.NaN\n",
    "            df['LOC_raw'] = df['LOC_raw'].interpolate()\n",
    "\n",
    "#Add column '%nominal load'\n",
    "    df['%nominal load']=df['Power current']/df['Power nominal']\n",
    "\n",
    "    #Export data for each engine\n",
    "    if export_data:\n",
    "        df_exp = df[df['%nominal load'] > treshold] #filter\n",
    "        df_exp = df_exp.reindex(sorted(df.columns), axis=1)\n",
    "        starttime_df=df.index[0].strftime('%y_%m_%d %H_%M')\n",
    "        endtime_df=df.index[-1].strftime('%y_%m_%d %H_%M')\n",
    "        with pd.ExcelWriter(f'{title} ({starttime_df} - {endtime_df}).xlsx') as writer:  \n",
    "            df_exp.to_excel(writer, float_format=\"%.3f\")\n",
    "\n",
    "    #Change time to be plotted (Logic: if plottime=downloadtime-> use that, otherwise see if thereis a date given)\n",
    "    if start_plot_at_downloadstart:\n",
    "        calc_time_plot_start=starttime.datetime\n",
    "    else:\n",
    "        try:\n",
    "            calc_time_plot_start=time_plot_start\n",
    "        except:\n",
    "            calc_time_plot_start=starttime.datetime\n",
    "    if end_plot_at_downloadend:\n",
    "        calc_time_plot_end=endtime.datetime\n",
    "    else:\n",
    "        try:\n",
    "            calc_time_plot_end=time_plot_end\n",
    "        except:\n",
    "            calc_time_plot_end=endtime.datetime  \n",
    "    calc_time_plot_start=calc_time_plot_start.replace(tzinfo=None)\n",
    "    calc_time_plot_end=calc_time_plot_end.replace(tzinfo=None)\n",
    "    mask = (df.index > calc_time_plot_start) & (df.index <= calc_time_plot_end)\n",
    "    df=df.loc[mask]\n",
    "\n",
    "    #Power load\n",
    "    loadprofile=[]\n",
    "    loadprofile.append((df['%nominal load'] < 0.2).sum()/len(df.index))\n",
    "    loadprofile.append(((df['%nominal load'] >= 0.2) & (df['%nominal load'] < 0.4)).sum()/len(df.index))# and (df['%nominal load'] < 0.4)\n",
    "    loadprofile.append(((df['%nominal load'] >= 0.4) & (df['%nominal load'] < 0.9)).sum()/len(df.index))\n",
    "    loadprofile.append((df['%nominal load'] >= 0.9).sum()/len(df.index))\n",
    "    loadrange.loc[len(loadrange)]=loadprofile\n",
    "    loadrange.rename({loadrange.index[-1]: eng.Name}, inplace=True)\n",
    "\n",
    "    #OPH/ Start\n",
    "    ophlist=[]\n",
    "    ophlist.append(df['Operating hours engine'].iloc[-1]-df['Operating hours engine'].iloc[0])\n",
    "    ophlist.append((df['Starts'].iloc[-1]-df['Starts'].iloc[0]).astype(int))\n",
    "    ophlist.append(ophlist[0]/ophlist[1])\n",
    "    starts_oph.loc[len(starts_oph)]=ophlist\n",
    "    starts_oph.rename({starts_oph.index[-1]: eng.Name}, inplace=True)\n",
    "\n",
    "    #Ignore values with too litte load with filter\n",
    "    if use_filter:\n",
    "        df = df[df['%nominal load'] > treshold] #filter\n",
    "\n",
    "    #Select interesting cylinders\n",
    "    if load_all_cylinders==True and rel_cyl!=all:\n",
    "        for cfg in pltcfg:\n",
    "            for y in cfg:\n",
    "                y=shrink_cylinder(y, rel_cyl)\n",
    "\n",
    "    #Change resolution\n",
    "    if change_timecycle_displayed:\n",
    "        try: #try if variable timecycle displayed created\n",
    "            stepsize=max(round(timecycle_displayed/timecycle),1)\n",
    "            df=df.iloc[::stepsize]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    #Store last LOC data values for data table at beginning of notebook\n",
    "    if 'LOC_average' in df.columns:\n",
    "        LOC_average_last.append(df['LOC_average'][-1])\n",
    "    else:\n",
    "        LOC_average_last.append(np.nan)\n",
    "\n",
    "    #Create ColumnDataSource (use CDS for connecting plots)\n",
    "    source = ColumnDataSource(df)\n",
    "\n",
    "    #Generate plots in Loop\n",
    "    plots=[]\n",
    "    x_dash=None\n",
    "    for i, cfg in enumerate(pltcfg):\n",
    "        if share_x_axes==True and i==1: #Setup shared x-axis or not\n",
    "            x_dash=plots[0].x_range\n",
    "            \n",
    "        plots.append(bokeh_chart(source, cfg, x_ax=x_axes, x_range=x_dash, title=plt_titles[i]))\n",
    "        \n",
    "\n",
    "    #Remove plots without renderers\n",
    "    to_remove=[]\n",
    "    for fig in plots:\n",
    "        if not fig.renderers:\n",
    "            print(f'{fig.title.text} plot has no data, not shown in the dashboard')\n",
    "            to_remove.append(fig)\n",
    "    plots = [e for e in plots if e not in to_remove]\n",
    "\n",
    "    ##Add timezone to times\n",
    "    berlin = pytz.timezone('Europe/Berlin')\n",
    "    starttime_disp=df.index[0].replace(tzinfo=pytz.utc).astimezone(berlin)\n",
    "    endtime_disp=df.index[-1].replace(tzinfo=pytz.utc).astimezone(berlin)\n",
    "\n",
    "    if make_tabs==True: #append to tabs or save in file\n",
    "        text1=Div(text='<h2>'+title+' ('+eng.serialNumber+'): '+starttime_disp.strftime('%Y-%m-%d %H:%M')+' - '+endtime_disp.strftime('%Y-%m-%d %H:%M')+'</h2>')\n",
    "        lay=layout(children=[text1,[plots]], sizing_mode='stretch_width')\n",
    "        tablist.append(Panel(child=lay, title=title))\n",
    "    else:\n",
    "        text1=Div(text='<h1>'+validation_name+': '+title+' ('+eng.serialNumber+'): '+'</h1><h2>'+starttime_disp.strftime('%Y-%m-%d %H:%M')+' - '+endtime_disp.strftime('%Y-%m-%d %H:%M')+'; '+filterstring)\n",
    "        lay=layout(children=[text1,[plots]], sizing_mode='stretch_width')\n",
    "        starttime_string=starttime_disp.strftime('%y_%m_%d %H_%M')\n",
    "        endtime_string=endtime_disp.strftime('%y_%m_%d %H_%M')\n",
    "        output_file(f'{title} ({starttime_string} - {endtime_string}).html', title=title) #Output in browser\n",
    "        save(lay) #save(layout) for saving only\n",
    "    \n",
    "    #print('')\n",
    "\n",
    "#Generate tab-layout and out\n",
    "if make_tabs:\n",
    "    if display_statistics:\n",
    "        tablist=tablist+[Panel(child=show_val_stats(vl, df_loadrange=loadrange, df_starts_oph=starts_oph), title='Statistics')]\n",
    " \n",
    "    tabs = Tabs(tabs=tablist)\n",
    "    main_title=Div(text='<h1>'+validation_name+': </h1><h2>'+filterstring)\n",
    "\n",
    "    from bokeh.models.widgets import DataTable, DateFormatter, TableColumn\n",
    "\n",
    "    df_dashboard=vl.dashboard\n",
    "    if 'LOC' in '\\#'.join(datastr):\n",
    "        df_dashboard['LOC']=np.round( [float(i) for i in LOC_average_last], 3)\n",
    "    Columns = [TableColumn(field=Ci, title=Ci) for Ci in df_dashboard.columns] # bokeh columns\n",
    "    data_table = DataTable(columns=Columns, source=ColumnDataSource(df_dashboard), autosize_mode='fit_columns', height=30*(len(df_dashboard.index)+1)) # bokeh table\n",
    "\n",
    "    test=layout(children=[main_title, data_table, tabs], sizing_mode='stretch_width')\n",
    "\n",
    "    #output_notebook() #output in Jupyter Notebook\n",
    "    starttime_string=starttime_disp.strftime('%y_%m_%d %H_%M')\n",
    "    endtime_string=endtime_disp.strftime('%y_%m_%d %H_%M')\n",
    "    output_file(f'{validation_name} ({starttime_string} - {endtime_string}).html', title=validation_name) #Output in browser\n",
    "    show(test)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c6f67f619c507261adfd1b3e240aa811c30c01a6fda948b8c554a6dc6da6c080"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
