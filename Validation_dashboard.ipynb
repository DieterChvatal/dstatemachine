{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Version 1.3 (Dieter's Integration to dstatemachine) \n",
    "\n",
    "from bokeh.io import push_notebook, show, output_notebook, save\n",
    "from bokeh.plotting import figure, output_file, show\n",
    "from bokeh.models import LinearAxis, Range1d, HoverTool\n",
    "from bokeh.layouts import column, row, gridplot, layout\n",
    "from bokeh.models import ColumnDataSource, Div\n",
    "from bokeh.models.widgets import Panel, Tabs\n",
    "import bokeh\n",
    "\n",
    "from itertools import cycle\n",
    "import dmyplant2\n",
    "from dmyplant2.dPlot import bokeh_chart, datastr_to_dict, expand_cylinder, shrink_cylinder, load_pltcfg_from_excel,show_val_stats\n",
    "import arrow\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import traceback\n",
    "import matplotlib\n",
    "import sys\n",
    "import warnings\n",
    "import logging\n",
    "import datetime\n",
    "import pytz\n",
    "import os \n",
    "\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
    "\n",
    "logging.basicConfig(\n",
    "    filename='dmyplant.log',\n",
    "    filemode='w',\n",
    "    format='%(asctime)s %(levelname)s, %(message)s',\n",
    "    level=logging.INFO\n",
    ")\n",
    "logging.captureWarnings(True)\n",
    "#hdlr = logging.StreamHandler(sys.stdout)\n",
    "#logging.getLogger().addHandler(hdlr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ce2976c71074c8d8f8e8d180ecfb957",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Load Data:   0%|                                  | 0/24 [00:00<?, ? datarows/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VAL Engines: 100%|████████████████████████| 15/15 [00:08<00:00,  1.71 engines/s]\n"
     ]
    }
   ],
   "source": [
    "dmyplant2.cred()\n",
    "mp = dmyplant2.MyPlant(0)\n",
    "from urllib3.exceptions import NewConnectionError\n",
    "import urllib\n",
    "import socket\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    class myEngine(dmyplant2.Engine):\n",
    "        @ property\n",
    "        def dash(self):\n",
    "            _dash = dict()\n",
    "            _dash['Name'] = self.Name\n",
    "            _dash['serialNumber'] = self.serialNumber\n",
    "            _dash['Site'] = self.get_property('IB Site Name') \n",
    "            _dash['Engine ID'] = self.get_property('Engine ID')\n",
    "            _dash['Design Number'] = self.get_property('Design Number')\n",
    "            _dash['Engine Type'] = self.get_property('Engine Type')\n",
    "            _dash['Engine Version'] = self.get_property('Engine Version')\n",
    "            _dash['Gas type'] = self.get_property('Gas Type')\n",
    "            _dash['Country'] = self.get_property('Country')\n",
    "            _dash['OPH Engine'] = self.Count_OpHour\n",
    "            _dash['OPH Validation'] = self.oph_parts\n",
    "            _dash['P_nom'] = self.Pmech_nominal\n",
    "            _dash['BMEP'] = self.BMEP\n",
    "            _dash['LOC'] = self.get_dataItem(\n",
    "                'RMD_ListBuffMAvgOilConsume_OilConsumption')\n",
    "            return _dash\n",
    "\n",
    "    dval=dmyplant2.Validation.load_def_excel('./Validation Dashboard/Input_validation_dashboard.xlsx', 'Engines', mp) #Loading of validation engine data from excel\n",
    "    vl = dmyplant2.Validation(mp, dval, lengine=myEngine, cui_log=False)\n",
    "    enginelist=vl.engines\n",
    "    logging.info('Engine properties loaded')\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    if str(e)==\"'Engine' object has no attribute 'asset'\":\n",
    "        print ('Possible cause: No internet connection')\n",
    "    #traceback.print_tb(e.__traceback__)\n",
    "    #sys.exit(1)\n",
    "  \n",
    "finally:\n",
    "    pass\n",
    "    #hdlr.close()\n",
    "    #logging.getLogger().removeHandler(hdlr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading of Variables from Excel automatic creation of variables\n",
    "df_var=pd.read_excel('./Validation Dashboard/Input_validation_dashboard.xlsx', sheet_name='Variables', usecols=['Variable', 'Value']) #loading of relevant excel sheet in DataFrame\n",
    "df_var.dropna(inplace=True)\n",
    "for i in range(len(df_var)):\n",
    "    globals()[df_var.Variable.iloc[i]]=df_var.Value.iloc[i]\n",
    "\n",
    "validation_name=str(validation_name)\n",
    "###check output,\n",
    "#check for cylinder list\n",
    "if display_all_cylinders:\n",
    "    rel_cyl=all\n",
    "else:\n",
    "    try: #see if variable rel_cyl initiated\n",
    "        rel_cyl=[int(y) for y in rel_cyl.split(',')]\n",
    "    except:\n",
    "        try:\n",
    "            rel_cyl=[int(rel_cyl)]\n",
    "        except:\n",
    "            rel_cyl=all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data for RWTH AACHEN   L2.7 light (mod) CR11.5)\n",
      "\n",
      "Downloading data for LOUISA MSPC   L3.1 reground CR12.5 \n",
      "\n",
      "Downloading data for Stadtwerke Rosenheim 624 L   L2.5 CR11.5   \n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'float' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 69\u001b[0m\n\u001b[0;32m     66\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatetime\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m#Add Column 'Operating hours validation'\u001b[39;00m\n\u001b[1;32m---> 69\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOperating hours validation\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mOperating hours engine\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43meng\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moph_start\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m#Add Column 'Starts validation'\u001b[39;00m\n\u001b[0;32m     72\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStarts validation\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStarts\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m-\u001b[39m eng\u001b[38;5;241m.\u001b[39mstarts_start\n",
      "File \u001b[1;32m~\\Documents\\Scripts\\dstatemachine\\venv\\lib\\site-packages\\pandas\\core\\ops\\common.py:81\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m     79\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[1;32m---> 81\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\Scripts\\dstatemachine\\venv\\lib\\site-packages\\pandas\\core\\arraylike.py:194\u001b[0m, in \u001b[0;36mOpsMixin.__sub__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__sub__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__sub__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m--> 194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_arith_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msub\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\Scripts\\dstatemachine\\venv\\lib\\site-packages\\pandas\\core\\series.py:6108\u001b[0m, in \u001b[0;36mSeries._arith_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   6106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_arith_method\u001b[39m(\u001b[38;5;28mself\u001b[39m, other, op):\n\u001b[0;32m   6107\u001b[0m     \u001b[38;5;28mself\u001b[39m, other \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39malign_method_SERIES(\u001b[38;5;28mself\u001b[39m, other)\n\u001b[1;32m-> 6108\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIndexOpsMixin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_arith_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\Scripts\\dstatemachine\\venv\\lib\\site-packages\\pandas\\core\\base.py:1348\u001b[0m, in \u001b[0;36mIndexOpsMixin._arith_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   1345\u001b[0m rvalues \u001b[38;5;241m=\u001b[39m ensure_wrapped_if_datetimelike(rvalues)\n\u001b[0;32m   1347\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1348\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marithmetic_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1350\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(result, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[1;32m~\\Documents\\Scripts\\dstatemachine\\venv\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:232\u001b[0m, in \u001b[0;36marithmetic_op\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m    228\u001b[0m     _bool_arith_check(op, left, right)\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;66;03m# error: Argument 1 to \"_na_arithmetic_op\" has incompatible type\u001b[39;00m\n\u001b[0;32m    231\u001b[0m     \u001b[38;5;66;03m# \"Union[ExtensionArray, ndarray[Any, Any]]\"; expected \"ndarray[Any, Any]\"\u001b[39;00m\n\u001b[1;32m--> 232\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43m_na_arithmetic_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res_values\n",
      "File \u001b[1;32m~\\Documents\\Scripts\\dstatemachine\\venv\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:171\u001b[0m, in \u001b[0;36m_na_arithmetic_op\u001b[1;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[0;32m    168\u001b[0m     func \u001b[38;5;241m=\u001b[39m partial(expressions\u001b[38;5;241m.\u001b[39mevaluate, op)\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 171\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    173\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_cmp \u001b[38;5;129;01mand\u001b[39;00m (is_object_dtype(left\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mor\u001b[39;00m is_object_dtype(right)):\n\u001b[0;32m    174\u001b[0m         \u001b[38;5;66;03m# For object dtype, fallback to a masked operation (only operating\u001b[39;00m\n\u001b[0;32m    175\u001b[0m         \u001b[38;5;66;03m#  on the non-missing values)\u001b[39;00m\n\u001b[0;32m    176\u001b[0m         \u001b[38;5;66;03m# Don't do this for comparisons, as that will handle complex numbers\u001b[39;00m\n\u001b[0;32m    177\u001b[0m         \u001b[38;5;66;03m#  incorrectly, see GH#32047\u001b[39;00m\n",
      "File \u001b[1;32m~\\Documents\\Scripts\\dstatemachine\\venv\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:239\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(op, a, b, use_numexpr)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m op_str \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    237\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_numexpr:\n\u001b[0;32m    238\u001b[0m         \u001b[38;5;66;03m# error: \"None\" not callable\u001b[39;00m\n\u001b[1;32m--> 239\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _evaluate_standard(op, op_str, a, b)\n",
      "File \u001b[1;32m~\\Documents\\Scripts\\dstatemachine\\venv\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:128\u001b[0m, in \u001b[0;36m_evaluate_numexpr\u001b[1;34m(op, op_str, a, b)\u001b[0m\n\u001b[0;32m    125\u001b[0m     _store_test_result(result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 128\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_evaluate_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\Documents\\Scripts\\dstatemachine\\venv\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:70\u001b[0m, in \u001b[0;36m_evaluate_standard\u001b[1;34m(op, op_str, a, b)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _TEST_MODE:\n\u001b[0;32m     69\u001b[0m     _store_test_result(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 70\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'float' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "tablist=[]\n",
    "LOC_average_last=[]\n",
    "loadrange=pd.DataFrame(columns=['<20%', '[20%, 40%)', '[40%, 90%)', '>=90%'])\n",
    "starts_oph=pd.DataFrame(columns=['OPH', 'Starts', 'OPH/ Start'])\n",
    "\n",
    "if use_filter:\n",
    "    filterstring=(f'Filter treshold {treshold}%')\n",
    "else:\n",
    "    filterstring=''#No filter applied'\n",
    "\n",
    "for eng_count, eng in enumerate(enginelist): \n",
    "    pltcfg, plt_titles=load_pltcfg_from_excel()\n",
    "\n",
    "    title=eng.Name\n",
    "\n",
    "    if load_all_cylinders==True:\n",
    "        cyl_to_load=all\n",
    "    else:\n",
    "        cyl_to_load=rel_cyl\n",
    "    datastr=[]\n",
    "    for cfg in pltcfg:\n",
    "        for y in cfg:\n",
    "            y=expand_cylinder(y, cyl_to_load, engi=eng)\n",
    "            datastr += y['col']\n",
    "\n",
    "\n",
    "    datastr += ['Operating hours engine','Starts',#manually add interesting dataitems, for specific calculation or x-axis #eventually method with calls if tems requested (for mean, LOC, filter...)\n",
    "    'Power current','Power nominal',#for filter\n",
    "    'Exhaust temperature cyl. average', #for delta values if string has Exhaust temperature delta\n",
    "    'Speed current', #For BMEP\n",
    "    'Starts', #for Starts validation\n",
    "    #Add custom variable: Mention all required values either here or in the definition excel\n",
    "        x_axes] #for value of x_axes\n",
    "\n",
    "    if 'Exhaust temperature delta' in '\\#'.join(datastr): datastr += ['Exhaust temperature'] #Add item if exhaust temperature delta wished\n",
    "    \n",
    "    ans=datastr_to_dict(datastr)\n",
    "    dat=ans[0]\n",
    "\n",
    "    if start_at_valstart:\n",
    "        starttime=eng.val_start\n",
    "    else:\n",
    "        try:\n",
    "            starttime=time_download_start\n",
    "        except:\n",
    "            starttime=eng.val_start\n",
    "    if get_recent_data:\n",
    "        endtime=arrow.utcnow()\n",
    "    else:\n",
    "        try:\n",
    "            endtime=arrow.get(time_download_end)\n",
    "        except:\n",
    "            endtime=arrow.utcnow()\n",
    "    starttime=arrow.get(starttime).to('Europe/Vienna')\n",
    "    endtime=endtime.to('Europe/Vienna')\n",
    "\n",
    "    print ('Downloading data for '+title)\n",
    "    df = eng.hist_data(\n",
    "            itemIds=dat,\n",
    "            p_from=starttime,\n",
    "            p_to=endtime,\n",
    "            timeCycle=timecycle)#, slot=eng_count)\n",
    "\n",
    "    ##Change Dataframe - make calculations\n",
    "    df.rename(columns = ans[1], inplace = True)\n",
    "    df = df.set_index('datetime')\n",
    "\n",
    "    #Add Column 'Operating hours validation'\n",
    "    df['Operating hours validation'] = df['Operating hours engine'] - eng.oph_start\n",
    "\n",
    "    #Add Column 'Starts validation'\n",
    "    df['Starts validation'] = df['Starts'] - eng.starts_start\n",
    "\n",
    "    #Add BMEP\n",
    "    if 'BMEP' in '\\#'.join(datastr):\n",
    "        df['BMEP'] = (1200*df['Power current']/eng.Generator_Efficiency)/(eng.engvol*df['Speed current'])\n",
    "\n",
    "\n",
    "    #Add custom value: Make calculation with syntax equal to examples above\n",
    "    #e.g. df['newName']=df['Operating hours engine]/df['Starts]\n",
    "    ####\n",
    "    ####\n",
    "    ####\n",
    "\n",
    "\n",
    "    #Calculate EGT delta\n",
    "    if 'Exhaust temperature delta' in '\\#'.join(datastr):\n",
    "        for col in df.columns:\n",
    "            if 'Exhaust temperature' in col and any(map(str.isdigit, col)) and not 'delta' in col:\n",
    "                df[f'Exhaust temperature delta cyl. {col[-2:]}']=df[col].sub(df['Exhaust temperature cyl. average'])\n",
    "\n",
    "    #Add LOC_average, LOC_raw\n",
    "    if 'LOC' in '\\#'.join(datastr):\n",
    "        dfres=eng.timestamp_LOC(starttime, endtime, windowsize=average_hours_LOC, return_OPH=True)\n",
    "        \n",
    "        df.sort_index(inplace=True) #additional sorting of index\n",
    "        df=pd.merge_asof(df, dfres, left_index=True, right_index=True)\n",
    "\n",
    "        duplicated=df.duplicated(subset=['LOC_average'])\n",
    "        df.loc[duplicated, ['LOC_average']] = np.NaN\n",
    "        df['LOC_average'] = df['LOC_average'].interpolate()\n",
    "\n",
    "        if interpolate_raw_LOC:\n",
    "            duplicated_raw=df.duplicated(subset=['LOC_raw'])\n",
    "            df.loc[duplicated_raw, ['LOC_raw']] = np.NaN\n",
    "            df['LOC_raw'] = df['LOC_raw'].interpolate()\n",
    "\n",
    "#Add column '%nominal load'\n",
    "    df['%nominal load']=df['Power current']/df['Power nominal']\n",
    "\n",
    "    #Export data for each engine\n",
    "    if export_data:\n",
    "        df_exp = df[df['%nominal load'] > treshold] #filter\n",
    "        df_exp = df_exp.reindex(sorted(df.columns), axis=1)\n",
    "        starttime_df=df.index[0].strftime('%y_%m_%d %H_%M')\n",
    "        endtime_df=df.index[-1].strftime('%y_%m_%d %H_%M')\n",
    "        with pd.ExcelWriter(f'{title} ({starttime_df} - {endtime_df}).xlsx') as writer:  \n",
    "            df_exp.to_excel(writer, float_format=\"%.3f\")\n",
    "\n",
    "    #Change time to be plotted (Logic: if plottime=downloadtime-> use that, otherwise see if thereis a date given)\n",
    "    if start_plot_at_downloadstart:\n",
    "        calc_time_plot_start=starttime.datetime\n",
    "    else:\n",
    "        try:\n",
    "            calc_time_plot_start=time_plot_start\n",
    "        except:\n",
    "            calc_time_plot_start=starttime.datetime\n",
    "    if end_plot_at_downloadend:\n",
    "        calc_time_plot_end=endtime.datetime\n",
    "    else:\n",
    "        try:\n",
    "            calc_time_plot_end=time_plot_end\n",
    "        except:\n",
    "            calc_time_plot_end=endtime.datetime  \n",
    "    calc_time_plot_start=calc_time_plot_start.replace(tzinfo=None)\n",
    "    calc_time_plot_end=calc_time_plot_end.replace(tzinfo=None)\n",
    "    mask = (df.index > calc_time_plot_start) & (df.index <= calc_time_plot_end)\n",
    "    df=df.loc[mask]\n",
    "\n",
    "    #Power load\n",
    "    loadprofile=[]\n",
    "    loadprofile.append((df['%nominal load'] < 0.2).sum()/len(df.index))\n",
    "    loadprofile.append(((df['%nominal load'] >= 0.2) & (df['%nominal load'] < 0.4)).sum()/len(df.index))# and (df['%nominal load'] < 0.4)\n",
    "    loadprofile.append(((df['%nominal load'] >= 0.4) & (df['%nominal load'] < 0.9)).sum()/len(df.index))\n",
    "    loadprofile.append((df['%nominal load'] >= 0.9).sum()/len(df.index))\n",
    "    loadrange.loc[len(loadrange)]=loadprofile\n",
    "    loadrange.rename({loadrange.index[-1]: eng.Name}, inplace=True)\n",
    "\n",
    "    #OPH/ Start\n",
    "    ophlist=[]\n",
    "    ophlist.append(df['Operating hours engine'].iloc[-1]-df['Operating hours engine'].iloc[0])\n",
    "    ophlist.append((df['Starts'].iloc[-1]-df['Starts'].iloc[0]).astype(int))\n",
    "    ophlist.append(ophlist[0]/ophlist[1])\n",
    "    starts_oph.loc[len(starts_oph)]=ophlist\n",
    "    starts_oph.rename({starts_oph.index[-1]: eng.Name}, inplace=True)\n",
    "\n",
    "    #Ignore values with too litte load with filter\n",
    "    if use_filter:\n",
    "        df = df[df['%nominal load'] > treshold] #filter\n",
    "\n",
    "    #Select interesting cylinders\n",
    "    if load_all_cylinders==True and rel_cyl!=all:\n",
    "        for cfg in pltcfg:\n",
    "            for y in cfg:\n",
    "                y=shrink_cylinder(y, rel_cyl)\n",
    "\n",
    "    #Change resolution\n",
    "    if change_timecycle_displayed:\n",
    "        try: #try if variable timecycle displayed created\n",
    "            stepsize=max(round(timecycle_displayed/timecycle),1)\n",
    "            df=df.iloc[::stepsize]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    #Store last LOC data values for data table at beginning of notebook\n",
    "    if 'LOC_average' in df.columns:\n",
    "        LOC_average_last.append(df['LOC_average'][-1])\n",
    "    else:\n",
    "        LOC_average_last.append(np.nan)\n",
    "\n",
    "    #Create ColumnDataSource (use CDS for connecting plots)\n",
    "    source = ColumnDataSource(df)\n",
    "\n",
    "    #Generate plots in Loop\n",
    "    plots=[]\n",
    "    x_dash=None\n",
    "    for i, cfg in enumerate(pltcfg):\n",
    "        if share_x_axes==True and i==1: #Setup shared x-axis or not\n",
    "            x_dash=plots[0].x_range\n",
    "            \n",
    "        plots.append(bokeh_chart(source, cfg, x_ax=x_axes, x_range=x_dash, title=plt_titles[i]))\n",
    "        \n",
    "\n",
    "    #Remove plots without renderers\n",
    "    to_remove=[]\n",
    "    for fig in plots:\n",
    "        if not fig.renderers:\n",
    "            print(f'{fig.title.text} plot has no data, not shown in the dashboard')\n",
    "            to_remove.append(fig)\n",
    "    plots = [e for e in plots if e not in to_remove]\n",
    "\n",
    "    ##Add timezone to times\n",
    "    berlin = pytz.timezone('Europe/Berlin')\n",
    "    starttime_disp=df.index[0].replace(tzinfo=pytz.utc).astimezone(berlin)\n",
    "    endtime_disp=df.index[-1].replace(tzinfo=pytz.utc).astimezone(berlin)\n",
    "\n",
    "    if make_tabs==True: #append to tabs or save in file\n",
    "        text1=Div(text='<h2>'+title+' ('+eng.serialNumber+'): '+starttime_disp.strftime('%Y-%m-%d %H:%M')+' - '+endtime_disp.strftime('%Y-%m-%d %H:%M')+'</h2>')\n",
    "        lay=layout(children=[text1,[plots]], sizing_mode='stretch_width')\n",
    "        tablist.append(Panel(child=lay, title=title))\n",
    "    else:\n",
    "        text1=Div(text='<h1>'+validation_name+': '+title+' ('+eng.serialNumber+'): '+'</h1><h2>'+starttime_disp.strftime('%Y-%m-%d %H:%M')+' - '+endtime_disp.strftime('%Y-%m-%d %H:%M')+'; '+filterstring)\n",
    "        lay=layout(children=[text1,[plots]], sizing_mode='stretch_width')\n",
    "        starttime_string=starttime_disp.strftime('%y_%m_%d %H_%M')\n",
    "        endtime_string=endtime_disp.strftime('%y_%m_%d %H_%M')\n",
    "        output_file(f'{title} ({starttime_string} - {endtime_string}).html', title=title) #Output in browser\n",
    "        save(lay) #save(layout) for saving only\n",
    "    \n",
    "    print('')\n",
    "\n",
    "#Generate tab-layout and out\n",
    "if make_tabs:\n",
    "    if display_statistics:\n",
    "        tablist=tablist+[Panel(child=show_val_stats(vl, df_loadrange=loadrange, df_starts_oph=starts_oph), title='Statistics')]\n",
    " \n",
    "    tabs = Tabs(tabs=tablist)\n",
    "    main_title=Div(text='<h1>'+validation_name+': </h1><h2>'+filterstring)\n",
    "\n",
    "    from bokeh.models.widgets import DataTable, DateFormatter, TableColumn\n",
    "\n",
    "    df_dashboard=vl.dashboard\n",
    "    if 'LOC' in '\\#'.join(datastr):\n",
    "        df_dashboard['LOC']=np.round( [float(i) for i in LOC_average_last], 3)\n",
    "    Columns = [TableColumn(field=Ci, title=Ci) for Ci in df_dashboard.columns] # bokeh columns\n",
    "    data_table = DataTable(columns=Columns, source=ColumnDataSource(df_dashboard), autosize_mode='fit_columns', height=30*(len(df_dashboard.index)+1)) # bokeh table\n",
    "\n",
    "    test=layout(children=[main_title, data_table, tabs], sizing_mode='stretch_width')\n",
    "\n",
    "    #output_notebook() #output in Jupyter Notebook\n",
    "    starttime_string=starttime_disp.strftime('%y_%m_%d %H_%M')\n",
    "    endtime_string=endtime_disp.strftime('%y_%m_%d %H_%M')\n",
    "    output_file(f'{validation_name} ({starttime_string} - {endtime_string}).html', title=validation_name) #Output in browser\n",
    "    show(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c6f67f619c507261adfd1b3e240aa811c30c01a6fda948b8c554a6dc6da6c080"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
