{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Version 1.2\n",
    "\n",
    "from bokeh.io import push_notebook, show, output_notebook, save\n",
    "from bokeh.plotting import figure, output_file, show\n",
    "from bokeh.models import LinearAxis, Range1d, HoverTool, DataRange1d\n",
    "from bokeh.layouts import column, row, gridplot, layout\n",
    "from bokeh.models import ColumnDataSource, Div\n",
    "from bokeh.models.widgets import Panel, Tabs\n",
    "import bokeh\n",
    "\n",
    "from itertools import cycle\n",
    "import dmyplant2\n",
    "from dmyplant2.dPlot import datastr_to_dict, bokeh_chart_engine_comparison, show_val_stats \n",
    "import arrow\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import traceback\n",
    "import matplotlib\n",
    "import sys\n",
    "import warnings\n",
    "import logging\n",
    "import datetime\n",
    "import pytz\n",
    "\n",
    "def is_number(s):\n",
    "    \"\"\" Returns True is string is a number. \"\"\"\n",
    "    try:\n",
    "        float(s)\n",
    "        return math.isfinite(s)\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
    "\n",
    "logging.basicConfig(\n",
    "    filename='dmyplant.log',\n",
    "    filemode='w',\n",
    "    format='%(asctime)s %(levelname)s, %(message)s',\n",
    "    level=logging.INFO\n",
    ")\n",
    "logging.captureWarnings(True)\n",
    "hdlr = logging.StreamHandler(sys.stdout)\n",
    "logging.getLogger().addHandler(hdlr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44d3e6c065f04265ad15a079d32d70ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Load Data:   0%|                                  | 0/24 [00:00<?, ? datarows/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cae04abe0024be2958e948bd87d8ac8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Load Data:   0%|                                  | 0/24 [00:00<?, ? datarows/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VAL Engines: 100%|██████████████████████████| 3/3 [00:01<00:00,  2.15 engines/s]\n"
     ]
    }
   ],
   "source": [
    "dmyplant2.cred()\n",
    "mp = dmyplant2.MyPlant(0)\n",
    "from urllib3.exceptions import NewConnectionError\n",
    "import urllib\n",
    "import socket\n",
    "\n",
    "\n",
    "try:\n",
    "    class myEngine(dmyplant2.Engine):\n",
    "        @ property\n",
    "        def dash(self):\n",
    "            _dash = dict()\n",
    "            _dash['Name'] = self.Name\n",
    "            _dash['serialNumber'] = self.serialNumber\n",
    "            _dash['Site'] = self.get_property('IB Site Name') \n",
    "            _dash['Engine ID'] = self.get_property('Engine ID')\n",
    "            _dash['Design Number'] = self.get_property('Design Number')\n",
    "            _dash['Engine Type'] = self.get_property('Engine Type')\n",
    "            _dash['Engine Version'] = self.get_property('Engine Version')\n",
    "            _dash['Gas type'] = self.get_property('Gas Type')\n",
    "            _dash['Country'] = self.get_property('Country')\n",
    "            _dash['OPH Engine'] = self.Count_OpHour\n",
    "            _dash['OPH Validation'] = self.oph_parts\n",
    "            _dash['P_nom'] = self.Pmech_nominal\n",
    "            _dash['BMEP'] = self.BMEP\n",
    "            _dash['LOC'] = self.get_dataItem(\n",
    "                'RMD_ListBuffMAvgOilConsume_OilConsumption')\n",
    "            return _dash\n",
    "\n",
    "    dval=dmyplant2.Validation.load_def_excel('./Engine Comparison/Input_engine_comparison.xlsx', 'Engines', mp) #Loading of validation engine data from excel\n",
    "    vl = dmyplant2.Validation(mp, dval, lengine=myEngine, cui_log=False)\n",
    "    enginelist=vl.engines\n",
    "    logging.info('Engine properties loaded')\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    if str(e)==\"'Engine' object has no attribute 'asset'\":\n",
    "        print ('Possible cause: No internet connection')\n",
    "    #traceback.print_tb(e.__traceback__)\n",
    "    sys.exit(1)\n",
    "  \n",
    "finally:\n",
    "    hdlr.close()\n",
    "    logging.getLogger().removeHandler(hdlr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Loading of Variables from Excel automatic creation of variables\n",
    "df_var=pd.read_excel('./Engine Comparison/Input_engine_comparison.xlsx', 'Variables', usecols=['Variable', 'Value']) #loading of relevant excel sheet in DataFrame #loading of relevant excel sheet in DataFrame\n",
    "df_var.dropna(inplace=True)\n",
    "for i in range(len(df_var)):\n",
    "    globals()[df_var.Variable.iloc[i]]=df_var.Value.iloc[i]\n",
    "\n",
    "validation_name=str(validation_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data for ECOGEN ENERGY SYSTEMS BVBA\n",
      "Downloading data for BMW REGENSBURG M3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4af274d94a904b30ad0f2a659b5cf66a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Load Data:   0%|                               | 0/14249 [00:00<?, ? datarows/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34258ca1030a467eabc22315e3c49d20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Load Data:   0%|                               | 0/28498 [00:00<?, ? datarows/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data for REGENSBURG\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9af93c6a9b834f6096ffed7d5580a61d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Load Data:   0%|                               | 0/13913 [00:00<?, ? datarows/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fba120a938e749fa9b73bfaa50e2ee1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Load Data:   0%|                               | 0/27826 [00:00<?, ? datarows/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tablist=[]\n",
    "eng_names=[]\n",
    "df_app_all=pd.DataFrame()\n",
    "LOC_average_last=[]\n",
    "loadrange=pd.DataFrame(columns=['<20%', '[20%, 40%)', '[40%, 90%)', '>=90%'])\n",
    "starts_oph=pd.DataFrame(columns=['OPH', 'Starts', 'OPH/ Start'])\n",
    "\n",
    "if use_filter:\n",
    "    filterstring=(f'Filter treshold {treshold}%')\n",
    "else:\n",
    "    filterstring=''#No filter applied'\n",
    "\n",
    "for eng_count, eng in enumerate(enginelist): \n",
    "    df_cfg=pd.read_excel('./Engine Comparison/Input_engine_comparison.xlsx', sheet_name='Pltcfg', usecols=['Title', 'Variable', 'Unit', 'y-lim min', 'y-lim max'])\n",
    "\n",
    "    title=eng.Name\n",
    "\n",
    "    df_cfg.loc[:,'Variable']=df_cfg.loc[:,'Variable'].astype(str)\n",
    "    df_cfg.loc[:,'Title']=df_cfg.loc[:,'Title'].astype(str)\n",
    "    df_cfg.loc[:,'Unit']=df_cfg.loc[:,'Unit'].astype(str)\n",
    "    df_cfg=df_cfg[df_cfg['Variable']!='nan']\n",
    "\n",
    "    variables=df_cfg['Variable'].tolist()\n",
    "    variables=[item.replace('\\xa0', ' ') for item in variables]\n",
    "\n",
    "    datastr=list(variables)\n",
    "\n",
    "    datastr += ['Operating hours engine',#manually add interesting dataitems, for specific calculation or x-axis #eventually method with calls if tems requested (for mean, LOC, filter...)\n",
    "    'Power current','Power nominal',#for filter\n",
    "    'Speed current', #For BMEP\n",
    "    'Starts', #for Starts validation\n",
    "    #Add custom value: Mention all required values either here or in the definition excel\n",
    "        x_axes] #for value of x_axes\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if 'Exhaust temperature delta' in '\\#'.join(datastr): datastr += ['Exhaust temperature'] #Add item if exhaust temperature delta wished\n",
    "    \n",
    "    ans=datastr_to_dict(datastr)\n",
    "    dat=ans[0]\n",
    "\n",
    "    if start_at_valstart:\n",
    "        starttime=eng.val_start\n",
    "    else:\n",
    "        try:\n",
    "            starttime=time_download_start\n",
    "        except:\n",
    "            starttime=eng.val_start\n",
    "    if get_recent_data:\n",
    "        endtime=arrow.utcnow()\n",
    "    else:\n",
    "        try:\n",
    "            endtime=arrow.get(time_download_end)\n",
    "        except:\n",
    "            endtime=arrow.utcnow()\n",
    "    starttime=arrow.get(starttime).to('Europe/Vienna')\n",
    "    endtime=endtime.to('Europe/Vienna')\n",
    "\n",
    "    print ('Downloading data for '+title)\n",
    "    df = eng.hist_data(\n",
    "            itemIds=dat,\n",
    "            p_from=starttime,\n",
    "            p_to=endtime,\n",
    "            timeCycle=timecycle)#, slot=eng_count)\n",
    "\n",
    "    ##Change Dataframe - make calculations\n",
    "    df.rename(columns = ans[1], inplace = True)\n",
    "    df = df.set_index('datetime')\n",
    "\n",
    "    #Add Column 'Operating hours validation'\n",
    "    df['Operating hours validation'] = df['Operating hours engine'] - eng.oph_start\n",
    "\n",
    "    #Add Column 'Starts validation'\n",
    "    df['Starts validation'] = df['Starts'] - eng.starts_start\n",
    "\n",
    "    #Add BMEP\n",
    "    if 'BMEP' in '\\#'.join(datastr):\n",
    "        df['BMEP'] = (1200*df['Power current']/eng.Generator_Efficiency)/(eng.engvol*df['Speed current'])\n",
    "\n",
    "\n",
    "    #Add custom value: Make calculation with syntax equal to examples above\n",
    "    #e.g. df['newName']=df['Operating hours engine]/df['Starts]\n",
    "    ####\n",
    "    ####\n",
    "    ####\n",
    "\n",
    "\n",
    "    #Calculate EGT delta\n",
    "    if 'Exhaust temperature delta' in '\\#'.join(datastr):\n",
    "        for col in df.columns:\n",
    "            if 'Exhaust temperature' in col and any(map(str.isdigit, col)) and not 'delta' in col:\n",
    "                df[f'Exhaust temperature delta cyl. {col[-2:]}']=df[col].sub(df['Exhaust temperature cyl. average'])\n",
    "\n",
    "    #Add LOC_average, LOC_raw\n",
    "    if 'LOC' in '\\#'.join(datastr): \n",
    "        dfres=eng.timestamp_LOC(starttime, endtime, windowsize=average_hours_LOC, return_OPH=True)\n",
    "        df.sort_index(inplace=True) #additional sorting of index\n",
    "        df=pd.merge_asof(df, dfres, left_index=True, right_index=True)\n",
    "\n",
    "        duplicated=df.duplicated(subset=['LOC_average'])\n",
    "        df.loc[duplicated, ['LOC_average']] = np.NaN\n",
    "        df['LOC_average'] = df['LOC_average'].interpolate()\n",
    "\n",
    "        if interpolate_raw_LOC:\n",
    "            duplicated_raw=df.duplicated(subset=['LOC_raw'])\n",
    "            df.loc[duplicated_raw, ['LOC_raw']] = np.NaN\n",
    "            df['LOC_raw'] = df['LOC_raw'].interpolate()\n",
    "\n",
    "    #Add column '%nominal load'\n",
    "    df['%nominal load']=df['Power current']/df['Power nominal']\n",
    "\n",
    "    #Export data for each engine\n",
    "    if export_data:\n",
    "        df_exp = df[df['%nominal load'] > treshold] #filter\n",
    "        df_exp = df_exp.reindex(sorted(df.columns), axis=1)\n",
    "        starttime_df=df.index[0].strftime('%y_%m_%d %H_%M')\n",
    "        endtime_df=df.index[-1].strftime('%y_%m_%d %H_%M')\n",
    "        with pd.ExcelWriter(f'{dir_path}\\{title} ({starttime_df} - {endtime_df}).xlsx') as writer:  \n",
    "            df_exp.to_excel(writer, float_format=\"%.3f\")\n",
    "\n",
    "    #Power load\n",
    "    loadprofile=[]\n",
    "    loadprofile.append((df['%nominal load'] < 0.2).sum()/len(df.index))\n",
    "    loadprofile.append(((df['%nominal load'] >= 0.2) & (df['%nominal load'] < 0.4)).sum()/len(df.index))# and (df['%nominal load'] < 0.4)\n",
    "    loadprofile.append(((df['%nominal load'] >= 0.4) & (df['%nominal load'] < 0.9)).sum()/len(df.index))\n",
    "    loadprofile.append((df['%nominal load'] >= 0.9).sum()/len(df.index))\n",
    "    loadrange.loc[len(loadrange)]=loadprofile\n",
    "    loadrange.rename({loadrange.index[-1]: eng.Name}, inplace=True)\n",
    "\n",
    "    #OPH/ Start\n",
    "    ophlist=[]\n",
    "    ophlist.append(df['Operating hours engine'].iloc[-1]-df['Operating hours engine'].iloc[0])\n",
    "    ophlist.append((df['Starts'].iloc[-1]-df['Starts'].iloc[0]).astype(int))\n",
    "    ophlist.append(ophlist[0]/ophlist[1])\n",
    "    starts_oph.loc[len(starts_oph)]=ophlist\n",
    "    starts_oph.rename({starts_oph.index[-1]: eng.Name}, inplace=True) \n",
    "\n",
    "    #Ignore values with too litte load with filter\n",
    "    if use_filter:\n",
    "        df = df[df['%nominal load'] > treshold] #filter\n",
    "\n",
    "    #Create new df with changed column name and append to dflist\n",
    "    ##append engine name to columnname\n",
    "    df_app=df\n",
    "    df_app = df_app[df_app['Operating hours validation'].ne(df_app['Operating hours validation'].shift())]\n",
    "    df_app['Operating hours validation']=df_app['Operating hours validation'].round()\n",
    "    df_app=df_app.set_index('Operating hours validation')\n",
    "    df_app=df_app.add_prefix(title+'_@_')\n",
    "    df_app_all=df_app_all._append(df_app)\n",
    "    eng_names.append (title)\n",
    "\n",
    "    #Store last LOC data values for data table at beginning of notebook\n",
    "    if 'LOC_average' in df.columns:\n",
    "        LOC_average_last.append(df['LOC_average'][-1])\n",
    "    else:\n",
    "        LOC_average_last.append(np.nan)\n",
    "     \n",
    "\n",
    "#Create ColumnDataSource (use CDS for connecting plots)\n",
    "source = ColumnDataSource(df_app_all)\n",
    "\n",
    "#Generate plots in Loop\n",
    "plots=[]\n",
    "x_dash=None\n",
    "for i, variable in enumerate(variables):\n",
    "    rel_data = [eng_name + '_@_' + variable for eng_name in eng_names]\n",
    "    y=dict()\n",
    "    for entry in rel_data:\n",
    "        if 'col' in y:\n",
    "            y['col'].append(entry.replace('\\xa0', ' '))\n",
    "        else:\n",
    "            y['col']=[entry.replace('\\xa0', ' ')]\n",
    "\n",
    "    #set unit if given\n",
    "    if df_cfg.Unit.iloc[i]!='nan': #take first occurance of unit\n",
    "        y['unit']=df_cfg.Unit.iloc[i].replace('\\xa0', ' ')\n",
    "\n",
    "    #set y-limits if given\n",
    "    lim_min=df_cfg['y-lim min'].iloc[i]\n",
    "    lim_max=df_cfg['y-lim max'].iloc[i]\n",
    "    if is_number(lim_min) and is_number(lim_max):\n",
    "        y['ylim']=(lim_min, lim_max) #add tuple y lim\n",
    "\n",
    "    #set title if given, else use var name\n",
    "    if df_cfg.Title.iloc[i]!='nan': #take first occurance of unit\n",
    "        title=df_cfg.Title.iloc[i].replace('\\xa0', ' ')\n",
    "    else:\n",
    "        title=variable\n",
    "\n",
    "    cfg=[y]\n",
    "    if share_x_axes==True and i==1: #Setup shared x-axis or not\n",
    "        x_dash=plots[0].x_range\n",
    "\n",
    "    if variable=='LOC_average' or variable=='LOC_raw':\n",
    "        glyphstyle='line' #set linestyle for interplotated values at LOC\n",
    "    else:\n",
    "        glyphstyle='circle'\n",
    "\n",
    "    plots.append(bokeh_chart_engine_comparison(source, cfg, variable, eng_names, x_range=x_dash, x_ax=x_axes, x_ax_unit='h', title=title, style=glyphstyle))\n",
    "\n",
    "#Remove plots without renderers\n",
    "to_remove=[]\n",
    "for fig in plots:\n",
    "    if not fig.renderers:\n",
    "        print(f'{fig.title.text} plot has no data, not shown in the dashboard')\n",
    "        to_remove.append(fig)\n",
    "plots = [e for e in plots if e not in to_remove]\n",
    "\n",
    "    # ##Add timezone to times\n",
    "berlin = pytz.timezone('Europe/Berlin')\n",
    "starttime_disp=df.index[0].replace(tzinfo=pytz.utc).astimezone(berlin)\n",
    "endtime_disp=df.index[-1].replace(tzinfo=pytz.utc).astimezone(berlin)\n",
    "\n",
    "text1=Div(text='<h1>'+validation_name+': Comparison between engines</h1><h2>Validation start - '+endtime_disp.strftime('%Y-%m-%d %H:%M'))\n",
    "\n",
    "from bokeh.models.widgets import DataTable, DateFormatter, TableColumn\n",
    "\n",
    "df_dashboard=vl.dashboard\n",
    "if 'LOC' in '\\#'.join(datastr):\n",
    "    df_dashboard['LOC']=np.round( [float(i) for i in LOC_average_last], 3)\n",
    "Columns = [TableColumn(field=Ci, title=Ci) for Ci in df_dashboard.columns] # bokeh columns\n",
    "data_table = DataTable(columns=Columns, source=ColumnDataSource(df_dashboard), autosize_mode='fit_columns', height=30*(len(df_dashboard.index)+1)) # bokeh table\n",
    "\n",
    "\n",
    "if display_statistics:\n",
    "    plot_lay=layout(children=[[plots]], sizing_mode='stretch_width')\n",
    "    tablist=[Panel(child=plot_lay, title='Engine comparison'), Panel(child=show_val_stats(vl, df_loadrange=loadrange, df_starts_oph=starts_oph), title='Statistics')]\n",
    "    tabs = Tabs(tabs=tablist)\n",
    "    lay=layout(children=[text1, data_table, tabs], sizing_mode='stretch_width')\n",
    "else:\n",
    "    lay=layout(children=[text1, data_table, [plots]], sizing_mode='stretch_width')\n",
    "\n",
    "#'fix times'\n",
    "starttime_string=starttime_disp.strftime('%y_%m_%d %H_%M')\n",
    "endtime_string=endtime_disp.strftime('%y_%m_%d %H_%M')\n",
    "output_file(f'{validation_name} - Comparison between engines  (until {endtime_string}).html', title=f'{validation_name}: Comparison between engines') #Output in browser \n",
    "\n",
    "show(lay) #save(layout) for saving only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c6f67f619c507261adfd1b3e240aa811c30c01a6fda948b8c554a6dc6da6c080"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
